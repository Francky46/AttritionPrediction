{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francky46/AttritionPrediction/blob/main/AttritionPrediction2.0..ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "124bbaf532a0cd66"
      },
      "cell_type": "markdown",
      "source": [
        "# 1) Importation des librairies"
      ],
      "id": "124bbaf532a0cd66"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:45.088885Z",
          "start_time": "2025-01-27T08:38:45.086298Z"
        },
        "id": "45d03adf497a0cdf"
      },
      "cell_type": "code",
      "source": [
        "from cProfile import label\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pour la séparation des données en train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Pour la création et l'évaluation de modèles\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
        "\n",
        "# Pour l'optimisation des hyperparamètres\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "id": "45d03adf497a0cdf",
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "59d618d81bb602ef"
      },
      "cell_type": "markdown",
      "source": [
        "# 2) Chargement des données"
      ],
      "id": "59d618d81bb602ef"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:46.038352Z",
          "start_time": "2025-01-27T08:38:45.138723Z"
        },
        "id": "71cf01ea2425e2b1",
        "outputId": "fd95ad87-8e8e-4ec2-e855-934119149fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "# Lis les différents fichiers CSV\n",
        "folder = \"src/\"\n",
        "df_general = pd.read_csv(folder + \"general_data.csv\")\n",
        "df_emp_survey = pd.read_csv(folder + \"employee_survey_data.csv\")\n",
        "df_mgr_survey = pd.read_csv(folder + \"manager_survey_data.csv\")\n",
        "df_in_time = pd.read_csv(folder + \"in_time.csv\")\n",
        "df_out_time = pd.read_csv(folder + \"out_time.csv\")"
      ],
      "id": "71cf01ea2425e2b1",
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'src/general_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9bfad8685dff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lis les différents fichiers CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"src/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_general\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"general_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_emp_survey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"employee_survey_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_mgr_survey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"manager_survey_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/general_data.csv'"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "metadata": {
        "id": "7b1dc6ecee341936"
      },
      "cell_type": "markdown",
      "source": [
        "# 3) Exploration des données"
      ],
      "id": "7b1dc6ecee341936"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:46.170733Z",
          "start_time": "2025-01-27T08:38:46.110570Z"
        },
        "id": "7ea3ad16748652c9"
      },
      "cell_type": "code",
      "source": [
        "print(\"=== General Data ===\")\n",
        "print(df_general.head(), \"\\n\")\n",
        "print(df_general.info(), \"\\n\")\n",
        "\n",
        "print(\"=== Employee Survey Data ===\")\n",
        "print(df_emp_survey.head(), \"\\n\")\n",
        "print(df_emp_survey.info(), \"\\n\")\n",
        "\n",
        "print(\"=== Manager Survey Data ===\")\n",
        "print(df_mgr_survey.head(), \"\\n\")\n",
        "print(df_mgr_survey.info(), \"\\n\")\n",
        "\n",
        "print(\"=== In Time Data ===\")\n",
        "print(df_in_time.head(), \"\\n\")\n",
        "print(df_in_time.info(), \"\\n\")\n",
        "\n",
        "print(\"=== Out Time Data ===\")\n",
        "print(df_out_time.head(), \"\\n\")\n",
        "print(df_out_time.info(), \"\\n\")"
      ],
      "id": "7ea3ad16748652c9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "56a5842c9df8e5cd"
      },
      "cell_type": "markdown",
      "source": [
        " # 4) Fusion des données"
      ],
      "id": "56a5842c9df8e5cd"
    },
    {
      "metadata": {
        "id": "dc26c6ab46b3aff5"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.1) Merge general_data, employee_survey_data et manager_survey_data"
      ],
      "id": "dc26c6ab46b3aff5"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:46.246015Z",
          "start_time": "2025-01-27T08:38:46.239434Z"
        },
        "id": "53b9d56da45676f1"
      },
      "cell_type": "code",
      "source": [
        "df_merged = pd.merge(df_general, df_emp_survey, on=\"EmployeeID\")\n",
        "df_merged = pd.merge(df_merged, df_mgr_survey, on=\"EmployeeID\")"
      ],
      "id": "53b9d56da45676f1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "70fdc0b02f93464a"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2) Calculer le nombre d'heures travaillées par jour\n",
        "On va aussi créer des features à partir de df_in_time et df_out_time (par exemple : nombre d'heures travaillées moyennes). </br>\n",
        "Les colonnes de in_time / out_time sont des dates/heures pour chaque jour travaillé."
      ],
      "id": "70fdc0b02f93464a"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.052220Z",
          "start_time": "2025-01-27T08:38:46.310742Z"
        },
        "id": "947e4ad54d41597e"
      },
      "cell_type": "code",
      "source": [
        "#  - Pour chaque employé, on peut calculer la différence out_time - in_time (en heures) pour chaque jour.\n",
        "#  - Ensuite on peut faire la moyenne sur toutes les dates disponibles pour obtenir \"moyenne d'heures/jour\"\n",
        "\n",
        "# Replace Unnamed header by EmployeeID\n",
        "df_in_time.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
        "df_out_time.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
        "\n",
        "# Suppression de la première colonne \"EmployeeID\" pour faciliter les opérations (on la conserve à part)\n",
        "df_in_time_id = df_in_time['EmployeeID']\n",
        "df_out_time_id = df_out_time['EmployeeID']\n",
        "\n",
        "# On exclut la colonne 'EmployeeID' des dataframes pour ne traiter que les colonnes date/heure\n",
        "df_in_time_dates = df_in_time.drop(['EmployeeID'], axis=1)\n",
        "df_out_time_dates = df_out_time.drop(['EmployeeID'], axis=1)\n",
        "\n",
        "# Conversion des valeurs string en datetime pour permettre la soustraction des temps\n",
        "# Nota : Certaines valeurs sont \"NA\" => conversion en NaT\n",
        "df_in_time_dates = df_in_time_dates.apply(pd.to_datetime, errors='coerce')\n",
        "df_out_time_dates = df_out_time_dates.apply(pd.to_datetime, errors='coerce')\n",
        "\n",
        "# Calcul de la différence (out_time - in_time) par employé et par jour\n",
        "df_hours = df_out_time_dates - df_in_time_dates  # Résultat en format timedelta\n",
        "\n",
        "# Convertir les timedelta en nombre d'heures (float)\n",
        "df_hours = df_hours.apply(lambda x: x.dt.total_seconds() / 3600)\n",
        "\n",
        "# Exemple : Calcul d'une statistique agrégée (moyenne d'heures/jour travaillé) pour chaque employé\n",
        "df_hours_mean = df_hours.mean(axis=1)\n",
        "\n",
        "# On veut garder la différence entre StandardHours et mean_work_hours\n",
        "df_hours['mean_work_hours_diff'] = df_hours_mean - df_merged['StandardHours']\n",
        "\n",
        "# On peut aussi calculer le nombre de jours d'absence (journées entières manquantes => in_time = NA & out_time = NA)\n",
        "# ou le ratio de jours travaillés vs le total possible, etc.\n",
        "# Ci-dessous un exemple de calcul du nombre de jours (colonnes) pour lesquels l'entrée est manquante\n",
        "nb_jours_total = df_hours.shape[1] - 1  # -1 car la dernière colonne est 'mean_work_hours' qu'on vient d'ajouter\n",
        "df_hours['absent_days'] = df_hours.iloc[:, :-1].isna().sum(axis=1)  # On ne compte pas la col. 'mean_work_hours'\n",
        "\n",
        "# Concaténer EmployeeID pour pouvoir refusionner\n",
        "df_hours_final = pd.concat([df_in_time_id, df_hours[['mean_work_hours_diff','absent_days']]], axis=1)\n",
        "\n",
        "# Heure d'arrivé moyenne\n",
        "\n",
        "df_hours_final['Avg_Hours_In'] = df_in_time_dates.apply(\n",
        "    lambda row: row.dropna().dt.hour.mean() + row.dropna().dt.minute.mean() / 60\n",
        "    if not row.dropna().empty else None, axis=1\n",
        ")\n",
        "\n",
        "# Heure de départ moyenne\n",
        "\n",
        "df_hours_final['Avg_Hours_Out'] = df_out_time_dates.apply(\n",
        "    lambda row: row.dropna().dt.hour.mean() + row.dropna().dt.minute.mean() / 60\n",
        "    if not row.dropna().empty else None, axis=1\n",
        ")"
      ],
      "id": "947e4ad54d41597e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dd78ce3782756295"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.3) Merge avec df_merged pour rajouter ces nouvelles features"
      ],
      "id": "dd78ce3782756295"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.120297Z",
          "start_time": "2025-01-27T08:38:47.106168Z"
        },
        "id": "1c4b1a2d849d0160"
      },
      "cell_type": "code",
      "source": [
        "df_merged = pd.merge(df_merged, df_hours_final, on='EmployeeID', how='left')\n",
        "\n",
        "print(\"\\n=== Aperçu des données fusionnées ===\\n\")\n",
        "print(df_merged.head())\n",
        "print(df_merged.info())"
      ],
      "id": "1c4b1a2d849d0160",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse de la distribution normale des données"
      ],
      "metadata": {
        "id": "NV03Tx6HQnIX"
      },
      "id": "NV03Tx6HQnIX"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_normal_distribution(df, column_name, log_transform=False, log_base='10'):\n",
        "    \"\"\"\n",
        "    Trace un histogramme (densité) de la colonne `column_name` d'un DataFrame `df`\n",
        "    et superpose la courbe de la distribution normale basée sur la moyenne et\n",
        "    l'écart-type (sur données brutes ou log-transformées).\n",
        "\n",
        "    Paramètres:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Votre DataFrame\n",
        "    column_name : str\n",
        "        Nom de la colonne à tracer\n",
        "    log_transform : bool\n",
        "        Si True, applique un log sur les valeurs de la colonne avant le tracé.\n",
        "    log_base : str\n",
        "        - '10' pour un log base 10 (log10)\n",
        "        - 'e' pour un log naturel (ln)\n",
        "    \"\"\"\n",
        "    data = df[column_name].dropna()\n",
        "\n",
        "    if log_transform:\n",
        "        if log_base == '10':\n",
        "            data = np.log10(data + 1)\n",
        "            suffix = \" (log10)\"\n",
        "        elif log_base == 'e':\n",
        "            data = np.log(data + 1)\n",
        "            suffix = \" (ln)\"\n",
        "        else:\n",
        "            raise ValueError(\"log_base doit être '10' ou 'e'\")\n",
        "    else:\n",
        "        suffix = \"\"\n",
        "\n",
        "\n",
        "    mean = data.mean()\n",
        "    std = data.std()\n",
        "\n",
        "    x_min = mean - 3 * std\n",
        "    x_max = mean + 3 * std\n",
        "\n",
        "    if x_min == x_max:\n",
        "        x_min = mean - 1\n",
        "        x_max = mean + 1\n",
        "\n",
        "    x = np.linspace(x_min, x_max, 200)\n",
        "\n",
        "    pdf = norm.pdf(x, mean, std)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(data, kde=False, stat='density', bins=30, color='skyblue', label='Données')\n",
        "\n",
        "    plt.plot(x, pdf, color='red', linewidth=2, label='Distribution normale')\n",
        "    plt.xlim(x_min, x_max)\n",
        "\n",
        "    plt.title(f\"Distribution de la colonne: {column_name}{suffix}\")\n",
        "    plt.xlabel(f\"{column_name}{suffix}\")\n",
        "    plt.ylabel(\"Densité\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Y8gVwKT_QsiY"
      },
      "id": "Y8gVwKT_QsiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_normal_distribution(df_merged, 'MonthlyIncome', log_transform=False)\n",
        "plot_normal_distribution(df_merged, 'MonthlyIncome', log_transform=True, log_base='10')\n",
        "plot_normal_distribution(df_merged, 'mean_work_hours_diff', log_transform=False, log_base='10')"
      ],
      "metadata": {
        "id": "fWQdZYsqQ09z"
      },
      "id": "fWQdZYsqQ09z",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2820c7d5605eed20"
      },
      "cell_type": "markdown",
      "source": [
        "# 5) Nettoyage et préparation des données"
      ],
      "id": "2820c7d5605eed20"
    },
    {
      "metadata": {
        "id": "5a9b6e778e5377c0"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.1) Gérer les valeurs manquantes"
      ],
      "id": "5a9b6e778e5377c0"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.174692Z",
          "start_time": "2025-01-27T08:38:47.169880Z"
        },
        "id": "7bb686111f61c3ce"
      },
      "cell_type": "code",
      "source": [
        "# On regarde déjà combien de valeurs manquantes par colonne\n",
        "missing_values = df_merged.isnull().sum()\n",
        "print(\"\\n=== Nombre de valeurs manquantes par colonne ===\\n\", missing_values)"
      ],
      "id": "7bb686111f61c3ce",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.224229Z",
          "start_time": "2025-01-27T08:38:47.220647Z"
        },
        "id": "36fd2752b3b6e64b"
      },
      "cell_type": "code",
      "source": [
        "# Dropna sur la colonne Attrition car c'est notre target\n",
        "df_merged = df_merged.dropna(subset=['Attrition'])"
      ],
      "id": "36fd2752b3b6e64b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.279926Z",
          "start_time": "2025-01-27T08:38:47.275526Z"
        },
        "id": "ca2427042f08cf3c"
      },
      "cell_type": "code",
      "source": [
        "# Exemple d'imputation : pour 'mean_work_hours' et 'absent_days', on remplace les NaN par la moyenne\n",
        "# On privilégie la moyenne ici car les valeurs de type durée (heures) ne sont pas fortement bornées\n",
        "df_merged['mean_work_hours_diff'] = df_merged['mean_work_hours_diff'].fillna(df_merged['mean_work_hours_diff'].mean())\n",
        "print(f\"Filled missing values for column 'mean_work_hours_diff' with mean value {df_merged['mean_work_hours_diff'].mean()}\")\n",
        "df_merged['absent_days'] = df_merged['absent_days'].fillna(df_merged['absent_days'].mean())\n",
        "print(f\"Filled missing values for column 'absent_days' with mean value {df_merged['absent_days'].mean()}\")"
      ],
      "id": "ca2427042f08cf3c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.332710Z",
          "start_time": "2025-01-27T08:38:47.326594Z"
        },
        "id": "3bcb7a7cbf3faa1e"
      },
      "cell_type": "code",
      "source": [
        "# Pour les colonnes de satisfaction ou autres colonnes numériques manquantes, on peut aussi faire un fillna\n",
        "# On privilégie la médiane\n",
        "num_cols = ['EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance',\n",
        "            'JobInvolvement', 'PerformanceRating', 'TotalWorkingYears', 'NumCompaniesWorked',]\n",
        "for col in num_cols:\n",
        "    if col in df_merged.columns:\n",
        "        df_merged[col] = df_merged[col].fillna(df_merged[col].median())\n",
        "        print(f\"Filled missing values for column {col} with median value {df_merged[col].median()}\")\n"
      ],
      "id": "3bcb7a7cbf3faa1e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f1cf019fe192eb53"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.2) Nettoyage de certaines colonnes (ex: Over18, EmployeeCount, StandardHours)"
      ],
      "id": "f1cf019fe192eb53"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.385065Z",
          "start_time": "2025-01-27T08:38:47.379072Z"
        },
        "id": "cd8762219021a0a5"
      },
      "cell_type": "code",
      "source": [
        "# On remarque souvent dans ce dataset \"EmployeeCount\" est toujours 1 => pas d'intérêt\n",
        "# \"Over18\" est toujours \"Y\", \"StandardHours\" est souvent 8 => on peut les drop\n",
        "cols_to_drop = ['Over18','StandardHours','EmployeeCount']\n",
        "for c in cols_to_drop:\n",
        "    if c in df_merged.columns:\n",
        "        df_merged.drop(c, axis=1, inplace=True, errors='ignore')"
      ],
      "id": "cd8762219021a0a5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "1c95da9bd6241297"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.3) Conversion de colonnes catégorielles en numériques"
      ],
      "id": "1c95da9bd6241297"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.442663Z",
          "start_time": "2025-01-27T08:38:47.434602Z"
        },
        "id": "d947248ca8f41304"
      },
      "cell_type": "code",
      "source": [
        "# Par exemple, Attrition = Yes/No, Gender = Male/Female, etc.\n",
        "# On peut les encoder, soit via LabelEncoder, soit via OneHotEncoder\n",
        "# Commençons par un label encoding simple pour la variable cible\n",
        "\n",
        "df_merged['Attrition'] = df_merged['Attrition'].map({'Yes':1, 'No':0})\n",
        "\n",
        "# Autres colonnes catégorielles (BusinessTravel, Department, EducationField, Gender, MaritalStatus, JobRole...)\n",
        "cat_cols = ['BusinessTravel','Department','EducationField','Gender','MaritalStatus','JobRole']\n",
        "\n",
        "# On va faire un one-hot-encoding rapide:\n",
        "df_merged = pd.get_dummies(df_merged, columns=cat_cols, drop_first=True)"
      ],
      "id": "d947248ca8f41304",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "15e665b9971bbec1"
      },
      "cell_type": "markdown",
      "source": [
        "# 6) Séparation des données en train/test"
      ],
      "id": "15e665b9971bbec1"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.489216Z",
          "start_time": "2025-01-27T08:38:47.481745Z"
        },
        "id": "b75e224a476a1de4"
      },
      "cell_type": "code",
      "source": [
        "# On sépare la cible (Attrition) des features\n",
        "\n",
        "X = df_merged.drop(['EmployeeID','Attrition'], axis=1)\n",
        "y = df_merged['Attrition']\n",
        "\n",
        "# Ensuite on fait un split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ],
      "id": "b75e224a476a1de4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ba440a38f1d808be"
      },
      "cell_type": "markdown",
      "source": [
        "# 7) scaling et entraînement d'un modèle simple"
      ],
      "id": "ba440a38f1d808be"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.562265Z",
          "start_time": "2025-01-27T08:38:47.552581Z"
        },
        "id": "4f5d93c6722c17d0"
      },
      "cell_type": "code",
      "source": [
        "# Selon le modèle (Logistic Regression par exemple), il peut être intéressant de standardiser\n",
        "# Ici on va montrer un exemple de pipeline manuel (scaling + logistic regression).\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "id": "4f5d93c6722c17d0",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "b24bf4ba78ad12e7"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.1) Entrainement d'un modèle de Logistic Regression"
      ],
      "id": "b24bf4ba78ad12e7"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.619789Z",
          "start_time": "2025-01-27T08:38:47.606490Z"
        },
        "id": "b4402e4358f0af3f"
      },
      "cell_type": "code",
      "source": [
        "clf_lr = LogisticRegression(random_state=42, max_iter=500)\n",
        "clf_lr.fit(X_train_scaled, y_train)"
      ],
      "id": "b4402e4358f0af3f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "14bafbac95b52eb0"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.2) Prediction et évaluation"
      ],
      "id": "14bafbac95b52eb0"
    },
    {
      "metadata": {
        "id": "c3fdcdc214d274b3"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.1) Prediction"
      ],
      "id": "c3fdcdc214d274b3"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.731833Z",
          "start_time": "2025-01-27T08:38:47.728760Z"
        },
        "id": "5ae717bee20a0cab"
      },
      "cell_type": "code",
      "source": [
        "y_pred_lr = clf_lr.predict(X_test_scaled)\n",
        "y_proba_lr = clf_lr.predict_proba(X_test_scaled)[:,1]"
      ],
      "id": "5ae717bee20a0cab",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5bcb83ca218971a8"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.2) Evaluation"
      ],
      "id": "5bcb83ca218971a8"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:47.799284Z",
          "start_time": "2025-01-27T08:38:47.787627Z"
        },
        "id": "9605cd8f008e1afd"
      },
      "cell_type": "code",
      "source": [
        "# Évaluation\n",
        "print(\"=== Évaluation Logistic Regression ===\")\n",
        "print(\"Accuracy : \", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"ROC AUC  : \", roc_auc_score(y_test, y_proba_lr))\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred_lr))\n",
        "print(\"Classification report :\\n\", classification_report(y_test, y_pred_lr))"
      ],
      "id": "9605cd8f008e1afd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ac0b7aa33f9db48"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.3) Entrainement d'un modèle de Random Forest"
      ],
      "id": "ac0b7aa33f9db48"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-28T16:18:42.829550Z",
          "start_time": "2025-01-28T16:18:42.186938Z"
        },
        "id": "ce2a502433dfc066"
      },
      "cell_type": "code",
      "source": [
        "clf_rf = RandomForestClassifier(random_state=42)\n",
        "clf_rf.fit(X_train, y_train)  # On peut le tester sans scaling\n",
        "y_pred_rf = clf_rf.predict(X_test)\n",
        "y_proba_rf = clf_rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\n=== Évaluation Random Forest ===\")\n",
        "print(\"Accuracy : \", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"ROC AUC  : \", roc_auc_score(y_test, y_proba_rf))\n",
        "print(\"Legende de la matrice de confusion :\")\n",
        "print(\"TN FP\")\n",
        "print(\"FN TP\")\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification report :\\n\", classification_report(y_test, y_pred_rf))"
      ],
      "id": "ce2a502433dfc066",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f29264be8969a2bc"
      },
      "cell_type": "markdown",
      "source": [
        "# 8) Optimisation des hyperparamètres"
      ],
      "id": "f29264be8969a2bc"
    },
    {
      "metadata": {
        "id": "cc5f76fd9f790aa4"
      },
      "cell_type": "markdown",
      "source": [
        "## 8.1) Tuning de la Logistic Regression"
      ],
      "id": "cc5f76fd9f790aa4"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:38:58.544505Z",
          "start_time": "2025-01-27T08:38:55.833895Z"
        },
        "id": "350a66b0af807a"
      },
      "cell_type": "code",
      "source": [
        "# Exemple de grille de paramètres (simple).\n",
        "# Attention : certaines combinaisons penalty/solver peuvent être incompatibles.\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],         # Coefficient de régularisation\n",
        "    'solver': ['liblinear', 'lbfgs'],     # Solveur\n",
        "    'max_iter': [100, 200, 500]           # Nombre itérations max\n",
        "    # 'penalty': ['l1','l2']  # <--- l1 nécessite solver='liblinear';\n",
        "                              #      si on veut tester l1, il faut ajuster la grille\n",
        "}\n",
        "\n",
        "# Création de l'instance LogisticRegression\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# GridSearchCV : 5-fold cross-validation, scoring basé sur l'accuracy (ou 'roc_auc', etc.)\n",
        "grid_lr = GridSearchCV(\n",
        "    estimator=lr_model,\n",
        "    param_grid=param_grid_lr,\n",
        "    scoring='accuracy',        # ou 'roc_auc'\n",
        "    cv=5,                      # 5 folds\n",
        "    verbose=1,                 # pour voir la progression\n",
        "    n_jobs=-1                  # utilise tous les coeurs dispo\n",
        ")\n",
        "\n",
        "# Entraînement du GridSearchCV\n",
        "grid_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Récupération des meilleurs paramètres et score\n",
        "print(\"=== Logistic Regression - Meilleurs hyperparamètres ===\")\n",
        "print(\"Best Params :\", grid_lr.best_params_)\n",
        "print(\"Best Score  :\", grid_lr.best_score_)\n",
        "\n",
        "# On peut maintenant re-prédire sur le test set avec le meilleur modèle trouvé\n",
        "best_lr = grid_lr.best_estimator_\n",
        "y_pred_best_lr = best_lr.predict(X_test_scaled)\n",
        "y_proba_best_lr = best_lr.predict_proba(X_test_scaled)[:,1]\n",
        "\n",
        "print(\"\\n=== Évaluation sur le jeu de test (LogisticRegression avec meilleurs params) ===\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_best_lr))\n",
        "print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba_best_lr))\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred_best_lr))\n",
        "print(\"Classification report :\\n\", classification_report(y_test, y_pred_best_lr))"
      ],
      "id": "350a66b0af807a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "b6600df29ea5de43"
      },
      "cell_type": "markdown",
      "source": [
        "### 8.1.1) Visualisation des résultats"
      ],
      "id": "b6600df29ea5de43"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:40:18.661599Z",
          "start_time": "2025-01-27T08:40:18.550418Z"
        },
        "id": "3175fdd6dbedfaf2"
      },
      "cell_type": "code",
      "source": [
        "# Exemple : on peut faire un DataFrame à partir de grid_lr.cv_results_ pour tracer un heatmap\n",
        "# entre C et max_iter, en séparant par solver.\n",
        "# Cela nécessite un pivot de la table.\n",
        "\n",
        "results_lr = pd.DataFrame(grid_lr.cv_results_)\n",
        "\n",
        "# Pour simplifier, on ne visualise que le solver='lbfgs', par exemple\n",
        "df_lbfgs = results_lr[ results_lr['param_solver'] == 'lbfgs' ]\n",
        "# Pivot => index: param_C, columns: param_max_iter, values: mean_test_score\n",
        "pivot_lbfgs = df_lbfgs.pivot(\n",
        "    index='param_C',\n",
        "    columns='param_max_iter',\n",
        "    values='mean_test_score'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(pivot_lbfgs, annot=True, cmap='viridis')\n",
        "plt.title(\"GridSearchCV - LogisticRegression (solver='lbfgs')\")\n",
        "plt.ylabel(\"C\")\n",
        "plt.xlabel(\"max_iter\")\n",
        "plt.show()"
      ],
      "id": "3175fdd6dbedfaf2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "209ce321f3dc5e31"
      },
      "cell_type": "markdown",
      "source": [
        "## 8.2) Tuning du Random Forest"
      ],
      "id": "209ce321f3dc5e31"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:41:28.987041Z",
          "start_time": "2025-01-27T08:41:16.124717Z"
        },
        "id": "e03c4276f189d994"
      },
      "cell_type": "code",
      "source": [
        "# Exemple de grille de paramètres\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "    # on peut rajouter 'max_features', 'min_samples_leaf', etc. selon les besoins\n",
        "}\n",
        "\n",
        "# l'objectif du random_state est de garantir la reproductibilité des résultats. La valeur 42 est arbitraire.\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring='accuracy',  # ou 'roc_auc'\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "print(\"\\n=== Random Forest - Meilleurs hyperparamètres ===\")\n",
        "print(\"Best Params :\", grid_rf.best_params_)\n",
        "print(\"Best Score  :\", grid_rf.best_score_)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_best_rf = best_rf.predict(X_test)\n",
        "y_proba_best_rf = best_rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\n=== Évaluation sur le jeu de test (RandomForest avec meilleurs params) ===\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_best_rf))\n",
        "print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba_best_rf))\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred_best_rf))\n",
        "print(\"Classification report :\\n\", classification_report(y_test, y_pred_best_rf))"
      ],
      "id": "e03c4276f189d994",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "58f2ea304693be56"
      },
      "cell_type": "markdown",
      "source": [
        "### 8.2.1) Visualisation des résultats"
      ],
      "id": "58f2ea304693be56"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:42:02.600812Z",
          "start_time": "2025-01-27T08:42:02.498032Z"
        },
        "id": "908a289f87b914e2"
      },
      "cell_type": "code",
      "source": [
        "results_rf = pd.DataFrame(grid_rf.cv_results_)\n",
        "\n",
        "# Exemple d'extraction de la partie n_estimators / max_depth (pivot sur 2 variables)\n",
        "# On fixe min_samples_split=2 par exemple pour la visualisation\n",
        "df_split2 = results_rf[ results_rf['param_min_samples_split'] == 2 ]\n",
        "\n",
        "pivot_rf = df_split2.pivot(\n",
        "    index='param_n_estimators',\n",
        "    columns='param_max_depth',\n",
        "    values='mean_test_score'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(pivot_rf, annot=True, cmap='coolwarm')\n",
        "plt.title(\"GridSearchCV - RandomForest (min_samples_split=2)\")\n",
        "plt.ylabel(\"n_estimators\")\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.show()"
      ],
      "id": "908a289f87b914e2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cfd0b6a5902c1f8"
      },
      "cell_type": "markdown",
      "source": [
        "# 9) Feature importance"
      ],
      "id": "cfd0b6a5902c1f8"
    },
    {
      "metadata": {
        "id": "a165d53c00bafbf7"
      },
      "cell_type": "markdown",
      "source": [
        "## 8.1) Random Forest"
      ],
      "id": "a165d53c00bafbf7"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:42:05.908544Z",
          "start_time": "2025-01-27T08:42:05.818567Z"
        },
        "id": "cd952ef566ac7f71"
      },
      "cell_type": "code",
      "source": [
        "# Par exemple, on peut rapidement regarder l'importance des features dans le Random Forest :\n",
        "importances = clf_rf.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "feat_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
        "print(\"\\n=== Feature importances (RandomForest) ===\\n\", feat_importances.head(10))\n",
        "\n",
        "# On peut éventuellement tracer un barplot pour visualiser\n",
        "plt.figure(figsize=(8,6))\n",
        "feat_importances.head(10).plot(kind='bar')\n",
        "plt.title(\"Top 10 des features les plus importantes (RandomForest)\")\n",
        "plt.show()\n"
      ],
      "id": "cd952ef566ac7f71",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8e86c9d09b9a08b0"
      },
      "cell_type": "markdown",
      "source": [
        "## 8.2) Logistic Regression"
      ],
      "id": "8e86c9d09b9a08b0"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T08:32:37.498898Z",
          "start_time": "2025-01-27T08:32:37.405125Z"
        },
        "id": "358304d63dc89c7d"
      },
      "cell_type": "code",
      "source": [
        "# Pour la régression logistique, on peut regarder les coefficients associés à chaque feature\n",
        "# On peut aussi regarder les coefficients les plus importants\n",
        "coefs = clf_lr.coef_[0]\n",
        "feat_coefs = pd.Series(coefs, index=feature_names).sort_values(ascending=False)\n",
        "print(\"\\n=== Coefficients (Logistic Regression) ===\\n\", feat_coefs.head(10))\n",
        "\n",
        "# On peut aussi tracer un barplot pour visualiser\n",
        "plt.figure(figsize=(8,6))\n",
        "feat_coefs.head(10).plot(kind='bar')\n",
        "plt.title(\"Top 10 des coefficients les plus importants (Logistic Regression)\")\n",
        "plt.show()"
      ],
      "id": "358304d63dc89c7d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "59554f52c7cbad24"
      },
      "cell_type": "markdown",
      "source": [
        "# 10) Evaluation finale"
      ],
      "id": "59554f52c7cbad24"
    },
    {
      "metadata": {
        "id": "d3c7d0d4d0f22e30"
      },
      "cell_type": "markdown",
      "source": [
        "## 10.1) Train et test scores"
      ],
      "id": "d3c7d0d4d0f22e30"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T12:42:41.932755Z",
          "start_time": "2025-01-27T12:42:41.841559Z"
        },
        "id": "7060a4c14a4a7873"
      },
      "cell_type": "code",
      "source": [
        "# On peut regarder les scores finaux sur le jeu de train et de test\n",
        "print(\"\\n=== Scores finaux ===\")\n",
        "print(\"Accuracy (Train) : \", accuracy_score(y_train, best_rf.predict(X_train)))\n",
        "print(\"Accuracy (Test)  : \", accuracy_score(y_test, y_pred_best_rf))\n",
        "print(\"ROC AUC  (Train) : \", roc_auc_score(y_train, best_rf.predict_proba(X_train)[:,1]))\n",
        "print(\"ROC AUC  (Test)  : \", roc_auc_score(y_test, y_proba_best_rf))"
      ],
      "id": "7060a4c14a4a7873",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "584090798eee38c3"
      },
      "cell_type": "markdown",
      "source": [
        "## 10.2) Courbe ROC"
      ],
      "id": "584090798eee38c3"
    },
    {
      "metadata": {
        "id": "ede554a708d6898f"
      },
      "cell_type": "markdown",
      "source": [
        "Nous pouvons constater que la courbe ROC a de bonnes performances pour le modèle Random Forest."
      ],
      "id": "ede554a708d6898f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-27T13:14:53.664333Z",
          "start_time": "2025-01-27T13:14:53.582732Z"
        },
        "id": "56e7b723c73ac2c1"
      },
      "cell_type": "code",
      "source": [
        "# On peut aussi tracer la courbe ROC\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_proba_best_rf)\n",
        "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_proba_best_lr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_rf, tpr_rf, label='RandomForest', c='b')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LogisticRegression', c='r')\n",
        "plt.plot([0,1], [0,1], '--', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Courbe ROC')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "56e7b723c73ac2c1",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}